{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "076905ba-5c2e-4a45-a9b5-44910d92e011",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/.local/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/02/12 18:34:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/02/12 18:34:07 WARN ExecutorAllocationManager: Dynamic allocation without a shuffle service is an experimental feature.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# New API\n",
    "spark_session = SparkSession.builder\\\n",
    "        .master(\"spark://192.168.2.51:7077\") \\\n",
    "        .appName(\"TianruZ_lecture1_example2\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.cores.max\", 4)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c75a94a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Project Gutenberg EBook of The Outline of Science, Vol. 1 (of 4), by ',\n",
       " 'J. Arthur Thomson',\n",
       " '',\n",
       " 'This eBook is for the use of anyone anywhere at no cost and with',\n",
       " 'almost no restrictions whatsoever.  You may copy it, give it away or']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book=spark_context.textFile('/home/ubuntu/20417.txt.utf-8')\n",
    "#book=spark_context.textFile('hdfs://192.168.2.70:9000/gutenberg.txt')\n",
    "book.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8828778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The',\n",
       "  'Project',\n",
       "  'Gutenberg',\n",
       "  'EBook',\n",
       "  'of',\n",
       "  'The',\n",
       "  'Outline',\n",
       "  'of',\n",
       "  'Science,',\n",
       "  'Vol.',\n",
       "  '1',\n",
       "  '(of',\n",
       "  '4),',\n",
       "  'by',\n",
       "  ''],\n",
       " ['J.', 'Arthur', 'Thomson'],\n",
       " [''],\n",
       " ['This',\n",
       "  'eBook',\n",
       "  'is',\n",
       "  'for',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'anyone',\n",
       "  'anywhere',\n",
       "  'at',\n",
       "  'no',\n",
       "  'cost',\n",
       "  'and',\n",
       "  'with'],\n",
       " ['almost',\n",
       "  'no',\n",
       "  'restrictions',\n",
       "  'whatsoever.',\n",
       "  '',\n",
       "  'You',\n",
       "  'may',\n",
       "  'copy',\n",
       "  'it,',\n",
       "  'give',\n",
       "  'it',\n",
       "  'away',\n",
       "  'or']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rdd.map(): Return a new RDD by applying a function to each element of this RDD.\n",
    "## split each line into seperated words\n",
    "book_sp=book.map(lambda x: x.split(\" \"))\n",
    "book_sp.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87878221",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The',\n",
       "  'Project',\n",
       "  'Gutenberg',\n",
       "  'EBook',\n",
       "  'of',\n",
       "  'The',\n",
       "  'Outline',\n",
       "  'of',\n",
       "  'Science,',\n",
       "  'Vol.',\n",
       "  '1',\n",
       "  '(of',\n",
       "  '4),',\n",
       "  'by',\n",
       "  ''],\n",
       " ['J.', 'Arthur', 'Thomson'],\n",
       " ['This',\n",
       "  'eBook',\n",
       "  'is',\n",
       "  'for',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'anyone',\n",
       "  'anywhere',\n",
       "  'at',\n",
       "  'no',\n",
       "  'cost',\n",
       "  'and',\n",
       "  'with'],\n",
       " ['almost',\n",
       "  'no',\n",
       "  'restrictions',\n",
       "  'whatsoever.',\n",
       "  '',\n",
       "  'You',\n",
       "  'may',\n",
       "  'copy',\n",
       "  'it,',\n",
       "  'give',\n",
       "  'it',\n",
       "  'away',\n",
       "  'or'],\n",
       " ['re-use',\n",
       "  'it',\n",
       "  'under',\n",
       "  'the',\n",
       "  'terms',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Project',\n",
       "  'Gutenberg',\n",
       "  'License',\n",
       "  'included']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rdd.filter(): Return a new RDD containing only the elements that satisfy a predicate.\n",
    "## for instance we can filter out sentences with too short phrases, which might be useless for analysis.\n",
    "book_sp_1=book_sp.filter(lambda x: len(x) > 1)\n",
    "book_sp_1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9948a52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'The',\n",
       " 'Outline',\n",
       " 'of',\n",
       " 'Science,',\n",
       " 'Vol.',\n",
       " '1',\n",
       " '(of',\n",
       " '4),',\n",
       " 'by',\n",
       " '',\n",
       " 'J.',\n",
       " 'Arthur',\n",
       " 'Thomson',\n",
       " 'This',\n",
       " 'eBook']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rdd.flatMap(): Return a new RDD by first applying a function to all elements of this RDD, and then flattening the results.\n",
    "## for example we can create single word RDD from previous result\n",
    "book_sw=book_sp_1.flatMap(lambda x: x)\n",
    "book_sw.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc73cfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, <pyspark.resultiterable.ResultIterable at 0x7f3c39d4eb90>),\n",
       " (8, <pyspark.resultiterable.ResultIterable at 0x7f3c39d4ebf0>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rdd.groupBy(): Return an RDD of grouped items. Can be used to group the RDD elements by some condition.\n",
    "## for example we group the words by their length.\n",
    "book_sw_fl = book_sw.groupBy(lambda x: len(x))\n",
    "book_sw_fl.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "359c81bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2,\n",
       "  ['of',\n",
       "   'of',\n",
       "   'by',\n",
       "   'J.',\n",
       "   'is',\n",
       "   'of',\n",
       "   'at',\n",
       "   'no',\n",
       "   'no',\n",
       "   'it',\n",
       "   'or',\n",
       "   'it',\n",
       "   'of',\n",
       "   'or',\n",
       "   'at',\n",
       "   'of',\n",
       "   '4)',\n",
       "   'J.',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'by',\n",
       "   'at',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'TO',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'BY',\n",
       "   'J.',\n",
       "   'OF',\n",
       "   'IN',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   '40',\n",
       "   'IN',\n",
       "   'IN',\n",
       "   'G.',\n",
       "   'P.',\n",
       "   'G.',\n",
       "   'P.',\n",
       "   'in',\n",
       "   'of',\n",
       "   'By',\n",
       "   'J.',\n",
       "   'it',\n",
       "   'it',\n",
       "   'to',\n",
       "   'it',\n",
       "   'of',\n",
       "   'is',\n",
       "   'it',\n",
       "   'of',\n",
       "   'of',\n",
       "   'is',\n",
       "   'of',\n",
       "   'of',\n",
       "   'It',\n",
       "   'be',\n",
       "   'to',\n",
       "   'in',\n",
       "   'to',\n",
       "   'it',\n",
       "   'is',\n",
       "   'it',\n",
       "   'is',\n",
       "   'in',\n",
       "   'to',\n",
       "   'be',\n",
       "   'of',\n",
       "   'of',\n",
       "   'an',\n",
       "   'at',\n",
       "   'of',\n",
       "   'is',\n",
       "   'it',\n",
       "   'of',\n",
       "   'at',\n",
       "   'of',\n",
       "   'is',\n",
       "   'is',\n",
       "   'of',\n",
       "   'It',\n",
       "   'is',\n",
       "   'to',\n",
       "   'in',\n",
       "   'of',\n",
       "   'by',\n",
       "   'to',\n",
       "   'to',\n",
       "   'he',\n",
       "   'no',\n",
       "   'of',\n",
       "   'by',\n",
       "   'an',\n",
       "   'of',\n",
       "   'of',\n",
       "   'to',\n",
       "   'up',\n",
       "   'as',\n",
       "   'on',\n",
       "   'be',\n",
       "   'to',\n",
       "   'of',\n",
       "   'To',\n",
       "   'it',\n",
       "   'in',\n",
       "   'to',\n",
       "   'be',\n",
       "   'he',\n",
       "   'he',\n",
       "   'on',\n",
       "   'he',\n",
       "   'be',\n",
       "   'to',\n",
       "   'of',\n",
       "   'to',\n",
       "   'of',\n",
       "   'is',\n",
       "   'to',\n",
       "   'to',\n",
       "   'be',\n",
       "   'to',\n",
       "   'is',\n",
       "   'to',\n",
       "   'be',\n",
       "   'an',\n",
       "   'to',\n",
       "   'an',\n",
       "   'of',\n",
       "   'of',\n",
       "   'We',\n",
       "   'to',\n",
       "   'by',\n",
       "   'to',\n",
       "   'of',\n",
       "   'of',\n",
       "   'It',\n",
       "   'we',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'we',\n",
       "   'is',\n",
       "   'of',\n",
       "   'is',\n",
       "   'to',\n",
       "   'is',\n",
       "   'of',\n",
       "   'is',\n",
       "   'of',\n",
       "   'of',\n",
       "   'L.',\n",
       "   'T.',\n",
       "   'is',\n",
       "   'by',\n",
       "   'of',\n",
       "   'as',\n",
       "   'as',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'is',\n",
       "   'to',\n",
       "   'of',\n",
       "   'is',\n",
       "   'of',\n",
       "   'of',\n",
       "   'at',\n",
       "   'is',\n",
       "   'we',\n",
       "   'it',\n",
       "   'if',\n",
       "   'it',\n",
       "   'is',\n",
       "   'to',\n",
       "   'be',\n",
       "   'I.',\n",
       "   'OF',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'on',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'OF',\n",
       "   '53',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'in',\n",
       "   'TO',\n",
       "   'of',\n",
       "   'of',\n",
       "   'V.',\n",
       "   'OF',\n",
       "   'of',\n",
       "   'of',\n",
       "   'in',\n",
       "   'in',\n",
       "   'ON',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'in',\n",
       "   'of',\n",
       "   'in',\n",
       "   'OF',\n",
       "   'in',\n",
       "   'to',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'in',\n",
       "   'of',\n",
       "   'of',\n",
       "   'is',\n",
       "   'of',\n",
       "   'of',\n",
       "   'OF',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'TO',\n",
       "   'OF',\n",
       "   '10',\n",
       "   'J.',\n",
       "   'C.',\n",
       "   '10',\n",
       "   'OF',\n",
       "   '10',\n",
       "   '11',\n",
       "   '14',\n",
       "   'BY',\n",
       "   '14',\n",
       "   'IN',\n",
       "   '31',\n",
       "   '15',\n",
       "   'at',\n",
       "   'OF',\n",
       "   '18',\n",
       "   'AT',\n",
       "   'AT',\n",
       "   '18',\n",
       "   'OF',\n",
       "   '19',\n",
       "   'IN',\n",
       "   'OF',\n",
       "   '19',\n",
       "   '20',\n",
       "   'of',\n",
       "   'OF',\n",
       "   '22',\n",
       "   '22',\n",
       "   'at',\n",
       "   '5,',\n",
       "   '23',\n",
       "   '23',\n",
       "   '23',\n",
       "   'E.',\n",
       "   'E.',\n",
       "   'AN',\n",
       "   'IT',\n",
       "   '24',\n",
       "   '28',\n",
       "   '29',\n",
       "   'by',\n",
       "   'AT',\n",
       "   '29',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   '32',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   '32',\n",
       "   '33',\n",
       "   '3,',\n",
       "   '33',\n",
       "   '36',\n",
       "   'OF',\n",
       "   '37',\n",
       "   'IN',\n",
       "   '37',\n",
       "   'IN',\n",
       "   '40',\n",
       "   '41',\n",
       "   '44',\n",
       "   '45',\n",
       "   'H.',\n",
       "   'J.',\n",
       "   '48',\n",
       "   'ON',\n",
       "   '49',\n",
       "   'H.',\n",
       "   'J.',\n",
       "   '49',\n",
       "   'By',\n",
       "   'A.',\n",
       "   '56',\n",
       "   '56',\n",
       "   '57',\n",
       "   'IS',\n",
       "   'TO',\n",
       "   'BE',\n",
       "   'IN',\n",
       "   '57',\n",
       "   '60',\n",
       "   'OF',\n",
       "   '61',\n",
       "   'OF',\n",
       "   '61',\n",
       "   'OF',\n",
       "   'UP',\n",
       "   'BY',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OR',\n",
       "   'OF',\n",
       "   '64',\n",
       "   'OF',\n",
       "   'OR',\n",
       "   'OF',\n",
       "   '65',\n",
       "   'J.',\n",
       "   'J.',\n",
       "   'IN',\n",
       "   'OF',\n",
       "   'BY',\n",
       "   'IN',\n",
       "   '65',\n",
       "   'by',\n",
       "   'of',\n",
       "   'OR',\n",
       "   '68',\n",
       "   'J.',\n",
       "   'J.',\n",
       "   '69',\n",
       "   'by',\n",
       "   'of',\n",
       "   '69',\n",
       "   '69',\n",
       "   '72',\n",
       "   'J.',\n",
       "   'J.',\n",
       "   'OF',\n",
       "   '72',\n",
       "   '72',\n",
       "   'J.',\n",
       "   'J.',\n",
       "   'OF',\n",
       "   '72',\n",
       "   'OF',\n",
       "   'TO',\n",
       "   '73',\n",
       "   '74',\n",
       "   'OF',\n",
       "   'IN',\n",
       "   'AN',\n",
       "   '76',\n",
       "   '76',\n",
       "   'OF',\n",
       "   '76',\n",
       "   '77',\n",
       "   'J.',\n",
       "   'J.',\n",
       "   '77',\n",
       "   'by',\n",
       "   'of',\n",
       "   'by',\n",
       "   'J.',\n",
       "   'H.',\n",
       "   '82',\n",
       "   '83',\n",
       "   'of',\n",
       "   'by',\n",
       "   'E.',\n",
       "   'IN',\n",
       "   '83',\n",
       "   'W.',\n",
       "   'S.',\n",
       "   '86',\n",
       "   '86',\n",
       "   'AN',\n",
       "   'OF',\n",
       "   '87',\n",
       "   'OF',\n",
       "   '90',\n",
       "   'to',\n",
       "   '90',\n",
       "   'J.',\n",
       "   'J.',\n",
       "   '91',\n",
       "   '91',\n",
       "   'of',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   '91',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   '92',\n",
       "   'OF',\n",
       "   'OR',\n",
       "   '94',\n",
       "   'AN',\n",
       "   '94',\n",
       "   'to',\n",
       "   '95',\n",
       "   'to',\n",
       "   'OR',\n",
       "   'OF',\n",
       "   '95',\n",
       "   'OF',\n",
       "   'AN',\n",
       "   'IN',\n",
       "   'OF',\n",
       "   'IN',\n",
       "   'IN',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'IS',\n",
       "   'BY',\n",
       "   'OF',\n",
       "   'BE',\n",
       "   'AN',\n",
       "   'OR',\n",
       "   'IS',\n",
       "   'W.',\n",
       "   'C.',\n",
       "   'AN',\n",
       "   'OF',\n",
       "   'J.',\n",
       "   'J.',\n",
       "   'OR',\n",
       "   'IN',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'AN',\n",
       "   'OF',\n",
       "   'TO',\n",
       "   'IN',\n",
       "   'IN',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'W.',\n",
       "   'S.',\n",
       "   'OF',\n",
       "   'ON',\n",
       "   'OR',\n",
       "   'OF',\n",
       "   'IN',\n",
       "   'A.',\n",
       "   'A.',\n",
       "   'W.',\n",
       "   'S.',\n",
       "   'W.',\n",
       "   'S.',\n",
       "   'IN',\n",
       "   'J.',\n",
       "   'J.',\n",
       "   'TO',\n",
       "   'AS',\n",
       "   'UP',\n",
       "   'SO',\n",
       "   'OF',\n",
       "   'OR',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'AN',\n",
       "   'J.',\n",
       "   'J.',\n",
       "   'G.',\n",
       "   'P.',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'by',\n",
       "   'J.',\n",
       "   'H.',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'IN',\n",
       "   'ON',\n",
       "   'J.',\n",
       "   'OF',\n",
       "   'T.',\n",
       "   'H.',\n",
       "   'of',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'AS',\n",
       "   'BY',\n",
       "   'J.',\n",
       "   'H.',\n",
       "   'OF',\n",
       "   'IS',\n",
       "   'AS',\n",
       "   'IT',\n",
       "   'IS',\n",
       "   'IN',\n",
       "   'OF',\n",
       "   'TO',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'by',\n",
       "   'J.',\n",
       "   'H.',\n",
       "   'by',\n",
       "   'J.',\n",
       "   'H.',\n",
       "   'AT',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'by',\n",
       "   'of',\n",
       "   'ON',\n",
       "   'OF',\n",
       "   'IN',\n",
       "   'TO',\n",
       "   'by',\n",
       "   'J.',\n",
       "   'H.',\n",
       "   'OF',\n",
       "   'LA',\n",
       "   'by',\n",
       "   'J.',\n",
       "   'H.',\n",
       "   'BY',\n",
       "   'A.',\n",
       "   'OF',\n",
       "   'IN',\n",
       "   'OF',\n",
       "   'IN',\n",
       "   'IN',\n",
       "   'OR',\n",
       "   'OF',\n",
       "   'IN',\n",
       "   'OF',\n",
       "   'IN',\n",
       "   'by',\n",
       "   'J.',\n",
       "   'H.',\n",
       "   'IN',\n",
       "   'OF',\n",
       "   'ON',\n",
       "   'by',\n",
       "   'of',\n",
       "   'ON',\n",
       "   'OF',\n",
       "   'ON',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'W.',\n",
       "   'S.',\n",
       "   'OR',\n",
       "   'AT',\n",
       "   'OF',\n",
       "   'IN',\n",
       "   'OR',\n",
       "   'IN',\n",
       "   'IN',\n",
       "   'OF',\n",
       "   'TO',\n",
       "   'TO',\n",
       "   'OF',\n",
       "   'TO',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'J.',\n",
       "   'J.',\n",
       "   'OF',\n",
       "   'AT',\n",
       "   'IS',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'IS',\n",
       "   'AT',\n",
       "   'TO',\n",
       "   'OF',\n",
       "   'ON',\n",
       "   'O.',\n",
       "   'J.',\n",
       "   'of',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'BY',\n",
       "   'AT',\n",
       "   '\"A',\n",
       "   'W.',\n",
       "   'S.',\n",
       "   'OR',\n",
       "   'OF',\n",
       "   'AN',\n",
       "   'OR',\n",
       "   'W.',\n",
       "   'S.',\n",
       "   'AT',\n",
       "   'TO',\n",
       "   'AT',\n",
       "   'F.',\n",
       "   'R.',\n",
       "   'OF',\n",
       "   'W.',\n",
       "   'S.',\n",
       "   'AN',\n",
       "   'IN',\n",
       "   'OF',\n",
       "   'W.',\n",
       "   'P.',\n",
       "   'W.',\n",
       "   'P.',\n",
       "   'OR',\n",
       "   'W.',\n",
       "   'S.',\n",
       "   'C.',\n",
       "   'J.',\n",
       "   'H.',\n",
       "   'W.',\n",
       "   'H.',\n",
       "   'OF',\n",
       "   'IS',\n",
       "   'of',\n",
       "   'OF',\n",
       "   'of',\n",
       "   'IS',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'IN',\n",
       "   'by',\n",
       "   'of',\n",
       "   'AN',\n",
       "   'OF',\n",
       "   'AN',\n",
       "   'by',\n",
       "   'of',\n",
       "   'IN',\n",
       "   'OF',\n",
       "   'TO',\n",
       "   'J.',\n",
       "   'J.',\n",
       "   'BY',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'R.',\n",
       "   'A.',\n",
       "   'by',\n",
       "   'of',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'IN',\n",
       "   'OF',\n",
       "   'by',\n",
       "   'of',\n",
       "   'BY',\n",
       "   'of',\n",
       "   'AN',\n",
       "   'AN',\n",
       "   'AN',\n",
       "   'of',\n",
       "   'H.',\n",
       "   'J.',\n",
       "   'OF',\n",
       "   'AN',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'ON',\n",
       "   'OF',\n",
       "   'ON',\n",
       "   'G.',\n",
       "   'ON',\n",
       "   'G.',\n",
       "   'of',\n",
       "   'is',\n",
       "   'of',\n",
       "   'in',\n",
       "   'it',\n",
       "   'be',\n",
       "   'we',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'be',\n",
       "   'it',\n",
       "   'is',\n",
       "   'if',\n",
       "   'of',\n",
       "   'to',\n",
       "   'in',\n",
       "   'be',\n",
       "   'of',\n",
       "   'No',\n",
       "   'to',\n",
       "   'in',\n",
       "   'or',\n",
       "   'on',\n",
       "   'It',\n",
       "   'is',\n",
       "   'be',\n",
       "   'to',\n",
       "   'in',\n",
       "   'is',\n",
       "   'to',\n",
       "   'of',\n",
       "   'So',\n",
       "   'OF',\n",
       "   'is',\n",
       "   'an',\n",
       "   'in',\n",
       "   'of',\n",
       "   'is',\n",
       "   'of',\n",
       "   'of',\n",
       "   'is',\n",
       "   'of',\n",
       "   'be',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'it',\n",
       "   'to',\n",
       "   'of',\n",
       "   'is',\n",
       "   'on',\n",
       "   'by',\n",
       "   'of',\n",
       "   'us',\n",
       "   'to',\n",
       "   'of',\n",
       "   'as',\n",
       "   'we',\n",
       "   'be',\n",
       "   'as',\n",
       "   'of',\n",
       "   'of',\n",
       "   'on',\n",
       "   'it',\n",
       "   'is',\n",
       "   'of',\n",
       "   'an',\n",
       "   'to',\n",
       "   'to',\n",
       "   'No',\n",
       "   'so',\n",
       "   'in',\n",
       "   'of',\n",
       "   'as',\n",
       "   'of',\n",
       "   'is',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'to',\n",
       "   'of',\n",
       "   'an',\n",
       "   'of',\n",
       "   'It',\n",
       "   'is',\n",
       "   'of',\n",
       "   'is',\n",
       "   'to',\n",
       "   'be',\n",
       "   'to',\n",
       "   'of',\n",
       "   'of',\n",
       "   'we',\n",
       "   'to',\n",
       "   'of',\n",
       "   'J.',\n",
       "   'J.',\n",
       "   'to',\n",
       "   'an',\n",
       "   'as',\n",
       "   'by',\n",
       "   'of',\n",
       "   'to',\n",
       "   'of',\n",
       "   'It',\n",
       "   'to',\n",
       "   'to',\n",
       "   'us',\n",
       "   'of',\n",
       "   'is',\n",
       "   'no',\n",
       "   'of',\n",
       "   'it',\n",
       "   'to',\n",
       "   'We',\n",
       "   'is',\n",
       "   'an',\n",
       "   'we',\n",
       "   'be',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'as',\n",
       "   'of',\n",
       "   'as',\n",
       "   'of',\n",
       "   'of',\n",
       "   'on',\n",
       "   'or',\n",
       "   'It',\n",
       "   'us',\n",
       "   'of',\n",
       "   'of',\n",
       "   'We',\n",
       "   'to',\n",
       "   'of',\n",
       "   'is',\n",
       "   'We',\n",
       "   'of',\n",
       "   'up',\n",
       "   'in',\n",
       "   'to',\n",
       "   'us',\n",
       "   'of',\n",
       "   'of',\n",
       "   'is',\n",
       "   'on',\n",
       "   'of',\n",
       "   'we',\n",
       "   'as',\n",
       "   'to',\n",
       "   'is',\n",
       "   'of',\n",
       "   'of',\n",
       "   'is',\n",
       "   'of',\n",
       "   'an',\n",
       "   'As',\n",
       "   'in',\n",
       "   'so',\n",
       "   'in',\n",
       "   'of',\n",
       "   'is',\n",
       "   'by',\n",
       "   'of',\n",
       "   'or',\n",
       "   'by',\n",
       "   'as',\n",
       "   'by',\n",
       "   'of',\n",
       "   'be',\n",
       "   'of',\n",
       "   'of',\n",
       "   'we',\n",
       "   'as',\n",
       "   'It',\n",
       "   'is',\n",
       "   'to',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'To',\n",
       "   'of',\n",
       "   'of',\n",
       "   'as',\n",
       "   'of',\n",
       "   'To',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'It',\n",
       "   'no',\n",
       "   'of',\n",
       "   'in',\n",
       "   'of',\n",
       "   'in',\n",
       "   'of',\n",
       "   'by',\n",
       "   'of',\n",
       "   'to',\n",
       "   'in',\n",
       "   'as',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'is',\n",
       "   'to',\n",
       "   'of',\n",
       "   'of',\n",
       "   'no',\n",
       "   'of',\n",
       "   'in',\n",
       "   'We',\n",
       "   'no',\n",
       "   'of',\n",
       "   'to',\n",
       "   'of',\n",
       "   'is',\n",
       "   'to',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'us',\n",
       "   'of',\n",
       "   'be',\n",
       "   'by',\n",
       "   'of',\n",
       "   'is',\n",
       "   'to',\n",
       "   'of',\n",
       "   'of',\n",
       "   'so',\n",
       "   'he',\n",
       "   'in',\n",
       "   'of',\n",
       "   'J.',\n",
       "   'OF',\n",
       "   'OF',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'to',\n",
       "   'us',\n",
       "   'is',\n",
       "   'he',\n",
       "   'as',\n",
       "   'is',\n",
       "   'in',\n",
       "   'as',\n",
       "   'of',\n",
       "   'of',\n",
       "   'is',\n",
       "   'to',\n",
       "   'be',\n",
       "   'as',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'of',\n",
       "   'be',\n",
       "   'or',\n",
       "   'of',\n",
       "   'we',\n",
       "   'it',\n",
       "   'to',\n",
       "   'by',\n",
       "   'it',\n",
       "   'be',\n",
       "   'we',\n",
       "   'is',\n",
       "   'of',\n",
       "   'in',\n",
       "   'Is',\n",
       "   'it',\n",
       "   'to',\n",
       "   'in',\n",
       "   'or',\n",
       "   'it',\n",
       "   'of',\n",
       "   'in',\n",
       "   ...]),\n",
       " (8,\n",
       "  ['Science,',\n",
       "   'anywhere',\n",
       "   'included',\n",
       "   'Science,',\n",
       "   'Produced',\n",
       "   'HYDROGEN',\n",
       "   'ABERDEEN',\n",
       "   \"PUTNAM'S\",\n",
       "   \"Putnam's\",\n",
       "   'Printing',\n",
       "   'Printing',\n",
       "   'Printing',\n",
       "   'Printing',\n",
       "   'Printing',\n",
       "   'Printing',\n",
       "   'Printing',\n",
       "   'Printing',\n",
       "   'Printing',\n",
       "   'Printing',\n",
       "   'Eleventh',\n",
       "   'Printing',\n",
       "   'Leibnitz',\n",
       "   'advances',\n",
       "   'possible',\n",
       "   'condense',\n",
       "   '\"Outline',\n",
       "   'Science\"',\n",
       "   'articles',\n",
       "   'onwards.',\n",
       "   'street,\"',\n",
       "   'hitherto',\n",
       "   'informal',\n",
       "   'articles',\n",
       "   'starting',\n",
       "   '\"Outline',\n",
       "   'Science\"',\n",
       "   'intended',\n",
       "   'appended',\n",
       "   'articles',\n",
       "   'indicate',\n",
       "   'journey.',\n",
       "   'widening',\n",
       "   'Science\"',\n",
       "   'declared',\n",
       "   'internal',\n",
       "   'growth.\"',\n",
       "   'Science\"',\n",
       "   'written.',\n",
       "   'science,',\n",
       "   'science,',\n",
       "   'sun--The',\n",
       "   'sea--The',\n",
       "   'sea--The',\n",
       "   'sea--The',\n",
       "   'STRUGGLE',\n",
       "   'arboreal',\n",
       "   'prospect',\n",
       "   'man--The',\n",
       "   'fountain',\n",
       "   'devices.',\n",
       "   'UNIVERSE',\n",
       "   'electron',\n",
       "   'becoming',\n",
       "   'HYDROGEN',\n",
       "   'Society.',\n",
       "   'PLANETS,',\n",
       "   'RELATIVE',\n",
       "   'ENTERING',\n",
       "   'ECLIPSE,',\n",
       "   'HYDROGEN',\n",
       "   'BOREALIS',\n",
       "   '(Messrs.',\n",
       "   'SUN-SPOT',\n",
       "   'NOVEMBER',\n",
       "   'Barnard,',\n",
       "   'PROVIDES',\n",
       "   'Drawings',\n",
       "   'Percival',\n",
       "   'HERCULES',\n",
       "   '100-INCH',\n",
       "   'SKELETON',\n",
       "   'ANIMALS,',\n",
       "   'GRANULES',\n",
       "   '(Natural',\n",
       "   'INCLINED',\n",
       "   'FLY-TRAP',\n",
       "   'INHABITS',\n",
       "   '(Natural',\n",
       "   'KANGAROO',\n",
       "   'CARRYING',\n",
       "   'SWOOPING',\n",
       "   'CAMBRIAN',\n",
       "   '(Natural',\n",
       "   'FEATHERS',\n",
       "   '(Natural',\n",
       "   'TRIASSIC',\n",
       "   'DUCKMOLE',\n",
       "   'PLATYPUS',\n",
       "   'SKELETON',\n",
       "   'INCREASE',\n",
       "   'Matthew.',\n",
       "   'EARLIEST',\n",
       "   'NAUTILUS',\n",
       "   'STARFISH',\n",
       "   'CAPTURED',\n",
       "   'OPEN-SEA',\n",
       "   '(Natural',\n",
       "   'SARGASSO',\n",
       "   'LAMPREYS',\n",
       "   'DEEP-SEA',\n",
       "   'DEEP-SEA',\n",
       "   'SKELETON',\n",
       "   'JAPANESE',\n",
       "   'DEEP-SEA',\n",
       "   'Amarus_)',\n",
       "   'CARRYING',\n",
       "   'HATCHING',\n",
       "   'SOUTHERN',\n",
       "   '(_Mantis',\n",
       "   'VARIABLE',\n",
       "   'SEASONAL',\n",
       "   'ATTITUDE',\n",
       "   'PARENTS,',\n",
       "   'RESEMBLE',\n",
       "   'APE-MAN,',\n",
       "   'GORILLA,',\n",
       "   'GORILLA,',\n",
       "   'APE-MAN,',\n",
       "   'RESTORED',\n",
       "   'MCGREGOR',\n",
       "   'ARBOREAL',\n",
       "   '(Natural',\n",
       "   'OFFSHOOT',\n",
       "   'PILTDOWN',\n",
       "   'SAND-PIT',\n",
       "   \"Osborn's\",\n",
       "   'ALTAMIRA',\n",
       "   'NORTHERN',\n",
       "   'PILTDOWN',\n",
       "   'modelled',\n",
       "   'modelled',\n",
       "   'NORTHERN',\n",
       "   'RHODESIA',\n",
       "   '(Natural',\n",
       "   'ARTISTIC',\n",
       "   'modelled',\n",
       "   \"Osborn's\",\n",
       "   'ENGRAVED',\n",
       "   'ALTAMIRA',\n",
       "   'NORTHERN',\n",
       "   'NAUTILUS',\n",
       "   'NAUTILUS',\n",
       "   'NAUTILUS',\n",
       "   'SHOEBILL',\n",
       "   'TROPICAL',\n",
       "   'PODARGUS',\n",
       "   'CATCHING',\n",
       "   'CATCHING',\n",
       "   'ANIMALS,',\n",
       "   \"AVOCET'S\",\n",
       "   'SIDEWAYS',\n",
       "   'SCOOPING',\n",
       "   'CATCHING',\n",
       "   'BREAKING',\n",
       "   \"FALCON'S\",\n",
       "   'SEIZING,',\n",
       "   'KILLING,',\n",
       "   \"PUFFIN'S\",\n",
       "   'CATCHING',\n",
       "   'CARRYING',\n",
       "   'HIND-LEG',\n",
       "   'MODIFIED',\n",
       "   '(_Birgus',\n",
       "   'Latro_),',\n",
       "   'GOSSAMER',\n",
       "   'GATEPOST',\n",
       "   'OPOSSUMS',\n",
       "   'FEIGNING',\n",
       "   'TOGETHER',\n",
       "   'SECRETED',\n",
       "   'BREEDING',\n",
       "   'Imperial',\n",
       "   'Imperial',\n",
       "   'PENGUINS',\n",
       "   'PECULIAR',\n",
       "   'Cagcombe',\n",
       "   'SPECIES,',\n",
       "   'ATTACHED',\n",
       "   'ALSATIAN',\n",
       "   'WOLF-DOG',\n",
       "   'LEOPARDS',\n",
       "   'MILLION?',\n",
       "   'BROWNIAN',\n",
       "   'MOVEMENT',\n",
       "   '(Messrs.',\n",
       "   'QUANTITY',\n",
       "   'To-day_.',\n",
       "   'National',\n",
       "   'Physical',\n",
       "   'ELECTRIC',\n",
       "   'RELATIVE',\n",
       "   'PRODUCED',\n",
       "   'MAGNETIC',\n",
       "   'COUNTING',\n",
       "   'Murray).',\n",
       "   'ELECTRIC',\n",
       "   'To-day_.',\n",
       "   'ELECTRIC',\n",
       "   'ELECTRON',\n",
       "   'To-day_.',\n",
       "   'MAGNETIC',\n",
       "   'ELECTRIC',\n",
       "   'ROTATING',\n",
       "   'ROTATING',\n",
       "   'abundant',\n",
       "   'evidence',\n",
       "   'deepened',\n",
       "   'interest',\n",
       "   'science.',\n",
       "   'interest',\n",
       "   'people.\"',\n",
       "   'certain,',\n",
       "   'however,',\n",
       "   'matter.\"',\n",
       "   'interest',\n",
       "   'progress',\n",
       "   'triumphs',\n",
       "   'predicts',\n",
       "   'chickens',\n",
       "   'disorder',\n",
       "   'disease.',\n",
       "   'Columbus',\n",
       "   'voyages,',\n",
       "   \"Darwin's\",\n",
       "   'mountain',\n",
       "   'animals,',\n",
       "   'chemical',\n",
       "   'elements',\n",
       "   'element,',\n",
       "   'primeval',\n",
       "   'derived,',\n",
       "   'powerful',\n",
       "   'profound',\n",
       "   'accurate',\n",
       "   'student,',\n",
       "   'complete',\n",
       "   'dynamic.',\n",
       "   'Thomson,',\n",
       "   'activity',\n",
       "   \"nature's\",\n",
       "   'secrets.',\n",
       "   'particle',\n",
       "   'theories',\n",
       "   'electron',\n",
       "   'electric',\n",
       "   'planets,',\n",
       "   'probable',\n",
       "   'question',\n",
       "   'evolved?',\n",
       "   'physics,',\n",
       "   'advances',\n",
       "   'instance',\n",
       "   'afforded',\n",
       "   'chemical',\n",
       "   'produced',\n",
       "   'ductless',\n",
       "   'thyroid,',\n",
       "   'Starling',\n",
       "   'chemical',\n",
       "   'regulate',\n",
       "   'hormones',\n",
       "   'patience',\n",
       "   'bacteria',\n",
       "   '_animal_',\n",
       "   'Sleeping',\n",
       "   'mastery.',\n",
       "   'heredity',\n",
       "   'educated',\n",
       "   'biology.',\n",
       "   'peopling',\n",
       "   'subjects',\n",
       "   'interest',\n",
       "   'devices,',\n",
       "   'insects,',\n",
       "   'mammals.',\n",
       "   'contacts',\n",
       "   'children',\n",
       "   'peoples;',\n",
       "   'deserve,',\n",
       "   'research',\n",
       "   'science,',\n",
       "   'conquest',\n",
       "   'kingdom.',\n",
       "   'THOMSON.',\n",
       "   'triumphs',\n",
       "   'Universe',\n",
       "   'problems',\n",
       "   'increase',\n",
       "   'entirely',\n",
       "   'duration',\n",
       "   'universe',\n",
       "   'Newcomb]',\n",
       "   'solution',\n",
       "   'regarded',\n",
       "   'ultimate',\n",
       "   'reaching',\n",
       "   'occupied',\n",
       "   'thinkers',\n",
       "   'Although',\n",
       "   'methods,',\n",
       "   'admitted',\n",
       "   'scarcely',\n",
       "   'duration',\n",
       "   'universe',\n",
       "   'millions',\n",
       "   'question',\n",
       "   'question',\n",
       "   'Heavenly',\n",
       "   'heavenly',\n",
       "   'distinct',\n",
       "   'relation',\n",
       "   'distance',\n",
       "   'Mercury,',\n",
       "   'Jupiter,',\n",
       "   'Neptune,',\n",
       "   'Mercury,',\n",
       "   'planets,',\n",
       "   'together',\n",
       "   'heavenly',\n",
       "   'distance',\n",
       "   'enormous',\n",
       "   'another.',\n",
       "   'straight',\n",
       "   'complete',\n",
       "   'journey.',\n",
       "   'greatest',\n",
       "   'comets),',\n",
       "   'compared',\n",
       "   'millions',\n",
       "   'distance',\n",
       "   'swimming',\n",
       "   'millions',\n",
       "   'distance',\n",
       "   'ascends.',\n",
       "   'greatest',\n",
       "   'theory.]',\n",
       "   'Verrier,',\n",
       "   'dramatic',\n",
       "   'distance',\n",
       "   'measures',\n",
       "   'rotation',\n",
       "   'Jupiter,',\n",
       "   'tranquil',\n",
       "   'movement',\n",
       "   'apparent',\n",
       "   'creeping',\n",
       "   'remember',\n",
       "   'addition',\n",
       "   'revolves',\n",
       "   'thousand',\n",
       "   'measures',\n",
       "   'straight',\n",
       "   'tangent.',\n",
       "   'tendency',\n",
       "   'circular',\n",
       "   'Circling',\n",
       "   'directly',\n",
       "   'directly',\n",
       "   'planets,',\n",
       "   'gigantic',\n",
       "   'planets,',\n",
       "   'spinning',\n",
       "   'distance',\n",
       "   'entirely',\n",
       "   'nearness',\n",
       "   'universe',\n",
       "   'millions',\n",
       "   'families',\n",
       "   'Universe',\n",
       "   'resolved',\n",
       "   'thousand',\n",
       "   'greatest',\n",
       "   'triumphs',\n",
       "   'relative',\n",
       "   'planets.',\n",
       "   'discover',\n",
       "   'distance',\n",
       "   'distance',\n",
       "   'distance',\n",
       "   'opposite',\n",
       "   'distance',\n",
       "   '\"shift.\"',\n",
       "   'recently',\n",
       "   'trillion',\n",
       "   'trillion',\n",
       "   'however,',\n",
       "   'heavens.',\n",
       "   'trillion',\n",
       "   'distance',\n",
       "   'distance',\n",
       "   'thousand',\n",
       "   'trillion',\n",
       "   'trillion',\n",
       "   'enormous',\n",
       "   'believed',\n",
       "   'colossal',\n",
       "   'universe',\n",
       "   'profound',\n",
       "   'Probably',\n",
       "   'familiar',\n",
       "   'making.\"',\n",
       "   'separate',\n",
       "   'them--or',\n",
       "   'millions',\n",
       "   'universe',\n",
       "   'effect.]',\n",
       "   'ENTERING',\n",
       "   'universe',\n",
       "   'anything',\n",
       "   'consider',\n",
       "   'problems',\n",
       "   'interest',\n",
       "   'distance',\n",
       "   'planets?',\n",
       "   'possess?',\n",
       "   'sporadic',\n",
       "   'meteors,',\n",
       "   'physical',\n",
       "   'appeared',\n",
       "   'arranged',\n",
       "   'universe',\n",
       "   'furnaces',\n",
       "   'resolved',\n",
       "   'simplest',\n",
       "   'commands',\n",
       "   'addition',\n",
       "   'absurdly',\n",
       "   'possible',\n",
       "   'greatest',\n",
       "   'requires',\n",
       "   'studied,',\n",
       "   'monument',\n",
       "   'deriving',\n",
       "   'sun--the',\n",
       "   'meteors:',\n",
       "   'screened',\n",
       "   'millions',\n",
       "   'probably',\n",
       "   'sunlight',\n",
       "   'although',\n",
       "   'detected',\n",
       "   'anywhere',\n",
       "   'universe',\n",
       "   'definite',\n",
       "   'somewhat',\n",
       "   'envelops',\n",
       "   'nothing.',\n",
       "   'luminous',\n",
       "   'envelope',\n",
       "   'vaporous',\n",
       "   'envelope',\n",
       "   'redness.',\n",
       "   'hydrogen',\n",
       "   'referred',\n",
       "   'surface.',\n",
       "   'shooting',\n",
       "   'dazzling',\n",
       "   'obscures',\n",
       "   'gigantic',\n",
       "   'however,',\n",
       "   'remained',\n",
       "   'previous',\n",
       "   'gigantic',\n",
       "   'portions',\n",
       "   'surface.',\n",
       "   'velocity',\n",
       "   'distance',\n",
       "   'minutes.',\n",
       "   'Tacchini',\n",
       "   'observed',\n",
       "   'greatest',\n",
       "   'diameter',\n",
       "   'them.[1]',\n",
       "   'ECLIPSE,',\n",
       "   'Carnegie',\n",
       "   'Carnegie',\n",
       "   'referred',\n",
       "   'surface.',\n",
       "   'believed',\n",
       "   'surface,',\n",
       "   'granular',\n",
       "   'enormous',\n",
       "   'activity',\n",
       "   'vapours.',\n",
       "   'dilutes,',\n",
       "   '\"oceans\"',\n",
       "   'gigantic',\n",
       "   'surface,',\n",
       "   'unknown,',\n",
       "   'suggests',\n",
       "   'interior',\n",
       "   'obdurate',\n",
       "   'enormous',\n",
       "   'contrast',\n",
       "   'enormous',\n",
       "   'covering',\n",
       "   'surface.',\n",
       "   'cavities',\n",
       "   'surface.',\n",
       "   'whirling',\n",
       "   'downward',\n",
       "   'currents',\n",
       "   'magnetic',\n",
       "   'magnetic',\n",
       "   'manifest',\n",
       "   'compass,',\n",
       "   'doubted,',\n",
       "   'although',\n",
       "   'definite',\n",
       "   'periodic',\n",
       "   'increase',\n",
       "   'diminish',\n",
       "   'minimum,',\n",
       "   'regular.',\n",
       "   'periodic',\n",
       "   'Nature\"_',\n",
       "   'BOREALIS',\n",
       "   'borealis',\n",
       "   'instant;',\n",
       "   'fan-like',\n",
       "   'glorious',\n",
       "   'obscure,',\n",
       "   'magnetic',\n",
       "   'rotating',\n",
       "   'complete',\n",
       "   'rotation',\n",
       "   'equator.',\n",
       "   'confirms',\n",
       "   'present,',\n",
       "   'elements',\n",
       "   'describe',\n",
       "   'describe',\n",
       "   'examined',\n",
       "   'luminous',\n",
       "   'lengths.',\n",
       "   'lengths.',\n",
       "   'rainbow.',\n",
       "   'shortest',\n",
       "   'rainbow,',\n",
       "   'length.)',\n",
       "   'simplest',\n",
       "   'prism--a',\n",
       "   'example)',\n",
       "   'colours.',\n",
       "   'sunlight',\n",
       "   'catching',\n",
       "   'coloured',\n",
       "   'composed',\n",
       "   'colours.',\n",
       "   'sunlight',\n",
       "   'colours,',\n",
       "   'colours,',\n",
       "   'produced',\n",
       "   'colours.',\n",
       "   'definite',\n",
       "   'position',\n",
       "   'possible',\n",
       "   'definite',\n",
       "   'sunlight',\n",
       "   'observed',\n",
       "   'constant',\n",
       "   'spectrum',\n",
       "   'displays',\n",
       "   'obvious,',\n",
       "   'spectrum',\n",
       "   'provides',\n",
       "   'presence',\n",
       "   'elements',\n",
       "   'SUN-SPOT',\n",
       "   'minutes.',\n",
       "   'markings',\n",
       "   'probably',\n",
       "   'Barnard,',\n",
       "   'November',\n",
       "   'chemical',\n",
       "   'spectrum',\n",
       "   'spectrum',\n",
       "   'reliable',\n",
       "   'spectrum',\n",
       "   'colours,',\n",
       "   'peculiar',\n",
       "   'Crossing',\n",
       "   'spectrum',\n",
       "   'hundreds',\n",
       "   'hundreds',\n",
       "   'envelope',\n",
       "   'envelope',\n",
       "   'register',\n",
       "   'spectrum',\n",
       "   'chemical',\n",
       "   'detected',\n",
       "   'minerals',\n",
       "   'elements',\n",
       "   'measure,',\n",
       "   'Movement',\n",
       "   'distance',\n",
       "   'measure.',\n",
       "   'movement',\n",
       "   'measure.',\n",
       "   'enormous',\n",
       "   'movement',\n",
       "   'luminous',\n",
       "   'spectrum',\n",
       "   'slightly',\n",
       "   'definite',\n",
       "   'position',\n",
       "   'luminous',\n",
       "   'shifting',\n",
       "   'spectral',\n",
       "   'opposite',\n",
       "   'measured',\n",
       "   'probably',\n",
       "   'revealed',\n",
       "   'watched,',\n",
       "   'measured',\n",
       "   'actually',\n",
       "   'PROVIDES',\n",
       "   'Spectrum',\n",
       "   'sunlight',\n",
       "   'colours.',\n",
       "   'composed',\n",
       "   'colours.',\n",
       "   'relieved',\n",
       "   'spectrum',\n",
       "   'ceasing.',\n",
       "   'Enormous',\n",
       "   'shooting',\n",
       "   'outwards',\n",
       "   'burning,',\n",
       "   'chemical',\n",
       "   'reaction',\n",
       "   'possible',\n",
       "   'chemical',\n",
       "   'reaction',\n",
       "   'ordinary',\n",
       "   'chemical',\n",
       "   'reaction',\n",
       "   'composed',\n",
       "   'material',\n",
       "   'present,',\n",
       "   'evidence',\n",
       "   'changes.',\n",
       "   'instead,',\n",
       "   'evidence',\n",
       "   'emitting',\n",
       "   'millions',\n",
       "   'addition',\n",
       "   'increase',\n",
       "   'decrease',\n",
       "   'greater.',\n",
       "   'Reliable',\n",
       "   'required',\n",
       "   'possibly',\n",
       "   'renewal.',\n",
       "   'acquired',\n",
       "   'enormous',\n",
       "   'present.',\n",
       "   'gravity.',\n",
       "   'another,',\n",
       "   'particle',\n",
       "   'attracts',\n",
       "   'diameter',\n",
       "   'millions',\n",
       "   'one-mile',\n",
       "   'straight',\n",
       "   'inwards,',\n",
       "   'movement',\n",
       "   'millions',\n",
       "   'meteoric',\n",
       "   'position',\n",
       "   'meteoric',\n",
       "   'required',\n",
       "   'reasons,',\n",
       "   'enormous',\n",
       "   'meteoric',\n",
       "   'definite',\n",
       "   'planets.',\n",
       "   'destined',\n",
       "   'maintain',\n",
       "   'question',\n",
       "   'elements',\n",
       "   'furnaces',\n",
       "   'planets,',\n",
       "   'limited.',\n",
       "   'families',\n",
       "   'planets,',\n",
       "   'Probably',\n",
       "   'planets,',\n",
       "   'Neptune.',\n",
       "   'probably',\n",
       "   'Mercury.',\n",
       "   'revolves',\n",
       "   'Mercury,',\n",
       "   'presents',\n",
       "   'broiling',\n",
       "   'opposite',\n",
       "   'markings',\n",
       "   'conceive',\n",
       "   'surface,',\n",
       "   '14.--THE',\n",
       "   'craters.',\n",
       "   'craters,',\n",
       "   'theories',\n",
       "   'Drawings',\n",
       "   \"planet's\",\n",
       "   '16.--THE',\n",
       "   'circular',\n",
       "   'breaking',\n",
       "   'supposed',\n",
       "   'advanced',\n",
       "   'millions',\n",
       "   'disposed',\n",
       "   'argument',\n",
       "   'supposes',\n",
       "   'disputed',\n",
       "   'Percival',\n",
       "   'lifelong',\n",
       "   'hundreds',\n",
       "   'straight',\n",
       "   'channels',\n",
       "   'broader.',\n",
       "   'however,',\n",
       "   'distance',\n",
       "   'reminded',\n",
       "   'distance',\n",
       "   'negative',\n",
       "   'millions',\n",
       "   'animals.',\n",
       "   'suppose,',\n",
       "   'possible',\n",
       "   'advanced',\n",
       "   'solution',\n",
       "   'Jupiter.',\n",
       "   'Jupiter,',\n",
       "   'however,',\n",
       "   'wondered',\n",
       "   'occupied',\n",
       "   'contains',\n",
       "   'material',\n",
       "   'nearness',\n",
       "   'contrary',\n",
       "   'planets,',\n",
       "   'Jupiter.',\n",
       "   'envelops',\n",
       "   'red-hot.',\n",
       "   'century.',\n",
       "   'seething',\n",
       "   'whirling',\n",
       "   'however,',\n",
       "   'interior',\n",
       "   'internal',\n",
       "   'surface.',\n",
       "   'Jupiter,',\n",
       "   'hours--a',\n",
       "   'seething',\n",
       "   'metallic',\n",
       "   'thousand',\n",
       "   'volcanic',\n",
       "   'material',\n",
       "   'combined',\n",
       "   'eleventh',\n",
       "   'nearness',\n",
       "   'evidence',\n",
       "   'planets,',\n",
       "   'planets?',\n",
       "   'Jupiter,',\n",
       "   'heavenly',\n",
       "   'surface.',\n",
       "   'Zeppelin',\n",
       "   'surface.',\n",
       "   'movement',\n",
       "   'volcanic',\n",
       "   'believes',\n",
       "   'probably',\n",
       "   'probably',\n",
       "   'supposed',\n",
       "   '\"Mare.\"]',\n",
       "   'tendency',\n",
       "   'below.)]',\n",
       "   'distinct',\n",
       "   'produced',\n",
       "   'relative',\n",
       "   'effects.',\n",
       "   'entering',\n",
       "   'floating',\n",
       "   'fourteen',\n",
       "   'absolute',\n",
       "   'followed',\n",
       "   'twilight',\n",
       "   'fourteen',\n",
       "   'straight',\n",
       "   'however,',\n",
       "   'farthest',\n",
       "   'enormous',\n",
       "   'surface.',\n",
       "   'thousand',\n",
       "   'believed',\n",
       "   'splashed',\n",
       "   'gigantic',\n",
       "   'volcanic',\n",
       "   'craters,',\n",
       "   'saucers.',\n",
       "   'Clavius,',\n",
       "   'thousand',\n",
       "   'moisture',\n",
       "   'agencies',\n",
       "   'conclude',\n",
       "   'meteors,',\n",
       "   'suddenly',\n",
       "   'overhead',\n",
       "   'perhaps,',\n",
       "   'friction',\n",
       "   'entirely',\n",
       "   'Millions',\n",
       "   'solitary',\n",
       "   'solitary',\n",
       "   '\"social\"',\n",
       "   'nucleus,',\n",
       "   'consists',\n",
       "   'approach',\n",
       "   'Whatever',\n",
       "   'enormous',\n",
       "   'however,',\n",
       "   'composed',\n",
       "   'thinnest',\n",
       "   'thousand',\n",
       "   'spectra.',\n",
       "   'elements',\n",
       "   'physical',\n",
       "   'chemical',\n",
       "   'HERCULES',\n",
       "   'distance',\n",
       "   'UNIVERSE',\n",
       "   'ordinary',\n",
       "   'recently',\n",
       "   'diameter',\n",
       "   'elements',\n",
       "   'thousand',\n",
       "   'distance',\n",
       "   'Hundreds',\n",
       "   'nebulous',\n",
       "   'heavens.',\n",
       "   'Possibly',\n",
       "   'theories',\n",
       "   'theories',\n",
       "   'analysed',\n",
       "   'spectrum',\n",
       "   'hottest.',\n",
       "   'research',\n",
       "   'dull-red',\n",
       "   'acquires',\n",
       "   'contract',\n",
       "   'cooling,',\n",
       "   'American',\n",
       "   'Russell,',\n",
       "   'question',\n",
       "   'received',\n",
       "   'answers.',\n",
       "   'commonly',\n",
       "   'accepted',\n",
       "   'luminous',\n",
       "   'heavens,',\n",
       "   'anything',\n",
       "   'hundreds',\n",
       "   'estimate',\n",
       "   'distance',\n",
       "   'evidence',\n",
       "   'composed',\n",
       "   'rarified',\n",
       "   'adequate',\n",
       "   'residual',\n",
       "   'ordinary',\n",
       "   'pressure',\n",
       "   'millions',\n",
       "   'faintest',\n",
       "   'although',\n",
       "   'physical',\n",
       "   'possible',\n",
       "   'terrific',\n",
       "   'luminous',\n",
       "   'supposed',\n",
       "   'condense',\n",
       "   'greatest',\n",
       "   'density,',\n",
       "   'process.',\n",
       "   'although',\n",
       "   'supposed',\n",
       "   'gigantic',\n",
       "   'formless',\n",
       "   'hundreds',\n",
       "   '\"spiral\"',\n",
       "   'heavens.',\n",
       "   'directly',\n",
       "   'appears,',\n",
       "   'striking',\n",
       "   'clusters',\n",
       "   'invented',\n",
       "   'opinions',\n",
       "   'reserve.',\n",
       "   'however,',\n",
       "   'universe',\n",
       "   '24.--THE',\n",
       "   'heavens.',\n",
       "   'system.]',\n",
       "   'emerging',\n",
       "   'opposite',\n",
       "   'nucleus?',\n",
       "   'opposite',\n",
       "   'interior',\n",
       "   'however,',\n",
       "   'received',\n",
       "   'variable',\n",
       "   'variable',\n",
       "   'directly',\n",
       "   'recently',\n",
       "   'regarded',\n",
       "   'revealed',\n",
       "   'invented',\n",
       "   'supposed',\n",
       "   'however,',\n",
       "   'hundreds',\n",
       "   'positive',\n",
       "   'universe',\n",
       "   '\"running',\n",
       "   'argument',\n",
       "   'universe',\n",
       "   'actually',\n",
       "   'universe',\n",
       "   'temporal',\n",
       "   'eternal;',\n",
       "   'declines',\n",
       "   'concedes',\n",
       "   'announce',\n",
       "   'imagines',\n",
       "   'reported',\n",
       "   'appeared',\n",
       "   'occurred',\n",
       "   'speeding',\n",
       "   'distance',\n",
       "   'outbreak',\n",
       "   'suddenly',\n",
       "   'renewing',\n",
       "   'suddenly',\n",
       "   'perceive',\n",
       "   'hydrogen',\n",
       "   'hundreds',\n",
       "   'collided',\n",
       "   'another,',\n",
       "   'nebulous',\n",
       "   'existed.',\n",
       "   'problems',\n",
       "   'tempting',\n",
       "   'positive',\n",
       "   'content,',\n",
       "   'occurred',\n",
       "   'thousand',\n",
       "   'trillion',\n",
       "   'outflame',\n",
       "   'hydrogen',\n",
       "   'UNIVERSE',\n",
       "   'Universe',\n",
       "   'question',\n",
       "   'Suppose,',\n",
       "   'heavens,',\n",
       "   'numerous',\n",
       "   'approach',\n",
       "   'consider',\n",
       "   'situated',\n",
       "   'possibly',\n",
       "   'entirely',\n",
       "   'majority',\n",
       "   'measured',\n",
       "   'drifting',\n",
       "   'opposite',\n",
       "   'velocity',\n",
       "   'relative',\n",
       "   'features',\n",
       "   'Venatici',\n",
       "   'suggests',\n",
       "   'central,',\n",
       "   'portion,',\n",
       "   'edge-on)',\n",
       "   'universe',\n",
       "   'accepted',\n",
       "   'estimate',\n",
       "   'material',\n",
       "   'central,',\n",
       "   'thousand',\n",
       "   'distance',\n",
       "   'suppose,',\n",
       "   ...])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_sw_fl.mapValues(list).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0627ee3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('The', <pyspark.resultiterable.ResultIterable at 0x7f3c39d4fbb0>),\n",
       " ('Project', <pyspark.resultiterable.ResultIterable at 0x7f3c39d4fc70>),\n",
       " ('EBook', <pyspark.resultiterable.ResultIterable at 0x7f3c39d4f670>),\n",
       " ('of', <pyspark.resultiterable.ResultIterable at 0x7f3c39d4fd00>),\n",
       " ('Outline', <pyspark.resultiterable.ResultIterable at 0x7f3c39d4fd60>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rdd.groupByKey(): Group the values for each key in the RDD into a single sequence, can be used to group RDD by key of elements.\n",
    "## NOTICE that the elements of RDD must be a (key,value) pair.\n",
    "## for example we can first construct (word,1) key-value pair, and then group by key, which is the word:\n",
    "book_sw_p = book_sw.map(lambda x: (x,1))\n",
    "book_wk=book_sw_p.groupByKey()\n",
    "book_wk.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fcac1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The',\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]),\n",
       " ('Project',\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use .mapValues() to pass each value in the key-value pair through a map function\n",
    "book_wk.mapValues(list).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f69a1da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('The', 876), ('Project', 78), ('EBook', 2), ('of', 5425), ('Outline', 7)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rdd.reduceByKey(): Merge the values for each key using an associative and commutative reduce function.\n",
    "## NOTICE that the elements of RDD must be a (key,value) pair.\n",
    "## for example we can reduce the (word,1) key-value pair, and do wordcount:\n",
    "from operator import add\n",
    "book_wordcount = book_sw_p.reduceByKey(add)\n",
    "book_wordcount.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b21de0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set hash seed to disable randomness\n",
    "import os\n",
    "os.environ[\"PYTHONHASHSEED\"]=str(123)\n",
    "# Frequency of the word 'Discovery'\n",
    "book_wordcount.lookup('Discovery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d901637",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Project',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Outline',\n",
       " 'Science,',\n",
       " 'Vol.',\n",
       " '1',\n",
       " '4),',\n",
       " '',\n",
       " 'Arthur',\n",
       " 'Thomson',\n",
       " 'is',\n",
       " 'use',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'at',\n",
       " 'no',\n",
       " 'restrictions',\n",
       " 'whatsoever.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_wordcount.keys().take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7a340cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before .distinct(): 122004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 19:>                                                         (0 + 1) / 2]\r",
      "\r",
      "[Stage 19:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After  .distinct(): 17955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 20:=============================>                            (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# rdd.distinct(): Return a new RDD containing the distinct elements in this RDD.\n",
    "# check the length of list before/after distinct\n",
    "print('Before .distinct():',book_sw.count())\n",
    "print('After  .distinct():',book_sw.distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28395e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('T', 'The'),\n",
       " ('P', 'Project'),\n",
       " ('G', 'Gutenberg'),\n",
       " ('E', 'EBook'),\n",
       " ('o', 'of')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rdd.keyBy(): Creates tuples of the elements in this RDD by applying f.\n",
    "## for example we can realize FirstLetterCount with this operation.\n",
    "book_sw.keyBy(lambda x: x[0]).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09d653ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('\"', 418),\n",
       " ('#', 1),\n",
       " ('$', 1),\n",
       " ('&', 12),\n",
       " (\"'\", 5),\n",
       " ('(', 391),\n",
       " ('*', 8),\n",
       " ('+', 1),\n",
       " ('-', 18),\n",
       " ('.', 1),\n",
       " ('0', 4),\n",
       " ('1', 356),\n",
       " ('2', 197),\n",
       " ('3', 71),\n",
       " ('4', 62),\n",
       " ('5', 50),\n",
       " ('6', 38),\n",
       " ('7', 30),\n",
       " ('8', 27),\n",
       " ('9', 31),\n",
       " ('=', 2),\n",
       " ('[', 246),\n",
       " ('_', 473),\n",
       " ('a', 12898),\n",
       " ('b', 4861),\n",
       " ('c', 4299),\n",
       " ('d', 2743),\n",
       " ('e', 3492),\n",
       " ('f', 4130),\n",
       " ('g', 1770),\n",
       " ('h', 3106),\n",
       " ('i', 8691),\n",
       " ('j', 344),\n",
       " ('k', 465),\n",
       " ('l', 2689),\n",
       " ('m', 4819),\n",
       " ('n', 2063),\n",
       " ('o', 9720),\n",
       " ('p', 3880),\n",
       " ('q', 173),\n",
       " ('r', 2505),\n",
       " ('s', 7411),\n",
       " ('t', 18600),\n",
       " ('u', 1110),\n",
       " ('v', 936),\n",
       " ('w', 5886),\n",
       " ('x', 32),\n",
       " ('y', 479),\n",
       " ('z', 55),\n",
       " ('{', 19),\n",
       " ('|', 142),\n",
       " ('', 77),\n",
       " ('', 6)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipelined operation\n",
    "sorted(                                  # sort the results by alphabet\n",
    "    book.map(lambda x: x.split(\" \"))     # split each line into seperated words\n",
    "    .filter(lambda x: len(x) > 0)        # filter out empty lines\n",
    "    .flatMap(lambda x: x)                # flatMap to single words\n",
    "    .filter(lambda x: len(x) > 0)        # filter out empty words\n",
    "    .keyBy(lambda x: x[0].lower())       # extract the first letter and covert to lower case\n",
    "    .map(lambda x: (x[0],1))             # create (first_letter, 1) pairs\n",
    "    .reduceByKey(add)                    # reduce the key-value pair by adding up\n",
    "    .collect()                           # collect the result\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c8c9c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('T', 'The', 1),\n",
       " ('P', 'Project', 1),\n",
       " ('G', 'Gutenberg', 1),\n",
       " ('E', 'EBook', 1),\n",
       " ('o', 'of', 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function and use it in spark\n",
    "def key_pair(x):\n",
    "    return (x[0],x,1)\n",
    "book_sw.map(key_pair).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b6438b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
